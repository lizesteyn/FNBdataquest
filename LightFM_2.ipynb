{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score, reciprocal_rank\n",
    "import numpy as np\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "import os\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./fnb_datav2.csv\")\n",
    "\n",
    "# Remove \n",
    "data = data.drop(columns = [\"item_descrip\", \"page\"])\n",
    "data.head(20)\n",
    "print((data[\"beh_segment\"] == \"B43\").any())\n",
    "# TEST:\n",
    "# Drop rows where \"item\" column contains \"NONE\"\n",
    "# data = data[data[\"active_ind\"] != \"Cold Start\"]\n",
    "data = data[data[\"item\"] != \"NONE\"]\n",
    "print((data[\"beh_segment\"] == \"B43\").any())\n",
    "data.head(20)\n",
    "# data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I remve a random Active user to test the cold start approach later:\n",
    "# # Step 1: Filter users with active_ind equal to 'Active'\n",
    "# active_users = data[data['active_ind'] == 'Active']\n",
    "\n",
    "# # Check if there are any active users\n",
    "# if not active_users.empty:\n",
    "#     # Step 2: Randomly select one of these users\n",
    "#     selected_user = active_users.sample(n=1)\n",
    "\n",
    "#     # Get the user id of the selected user\n",
    "#     selected_user_id = selected_user['idcol'].values[0]\n",
    "\n",
    "#     # Step 3: Move all entries of this selected user to a new dataframe\n",
    "#     selected_user_df = data[data['idcol'] == selected_user_id]\n",
    "\n",
    "#     # Step 4: Remove this user's entries from the original dataframe\n",
    "#     data = data[data['idcol'] != selected_user_id]\n",
    "\n",
    "# selected_user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking transactions for a specific ID:\n",
    "id = 77196041\n",
    "data[data[\"idcol\"]==id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following user features\n",
    "\"\"\"\n",
    "- weekly interaction frequency, \n",
    "- most frequenctly item interacted with (other than ALL),\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Give scores to the interactions, and then drop the interaction column:L\n",
    "# interaction_scores = {\n",
    "#     'CLICK': 1,\n",
    "#     'CHECKOUT': 2\n",
    "# }\n",
    "\n",
    "interaction_scores = {\n",
    "    'DISPLAY': 0,\n",
    "    'CLICK': 1,\n",
    "    'CHECKOUT': 2\n",
    "}\n",
    "\n",
    "# Map interaction scores, fill missing values with 0\n",
    "data['interaction_scores'] = data['interaction'].map(interaction_scores).fillna(0)\n",
    "\n",
    "# Add ids for each unique item\n",
    "data['item_id'] = pd.factorize(data['item'])[0]\n",
    "\n",
    "# data.drop(columns = [\"interaction\"])\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add User Features:\n",
    "\n",
    "#### Add the following user features\n",
    "- weekly interaction frequency - on average, over the whole dataset, how many times does the user interact per week\n",
    "- daily interaction frequency - similar to above\n",
    "- monthly interaction frequency - how many times \n",
    "- most frequenctly item interacted with (other than ALL) over the whole \n",
    "- most frequently interacted with item type\n",
    "- Ratio of checkout to click for each user-item combination (ask Lize)\n",
    "- Add an activity score, which is a metric that says how often, over the entire dataset, is the user active\n",
    "    - Done by dividing the number of unique active days by the number of days in the dataset\n",
    "- Potential other features to add from TOD:\n",
    "    - average time between clicking item\n",
    "    - average time between checking out the item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data =  data.copy()\n",
    "\n",
    "target_idcol = 77196041\n",
    "index = int(original_data[original_data['idcol'] == target_idcol].index[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user daily activity score:\n",
    "# On days that they are active, how many interactions do they make?\n",
    "# Convert int_date to datetime\n",
    "data['int_date'] = pd.to_datetime(data['int_date'], format='%d%b%Y')\n",
    "\n",
    "# Group by idcol to calculate total interactions and unique active days\n",
    "user_interactions = data.groupby('idcol').size().reset_index(name='total_interactions')\n",
    "active_days = data.groupby('idcol')['int_date'].nunique().reset_index(name='unique_active_days')\n",
    "\n",
    "# Merge the results to calculate daily_activity_score\n",
    "user_activity = pd.merge(user_interactions, active_days, on='idcol')\n",
    "user_activity['daily_activity_score'] = user_activity['total_interactions'] / user_activity['unique_active_days']\n",
    "\n",
    "# Merge the daily_activity_score back to the original DataFrame\n",
    "data = pd.merge(data, user_activity[['idcol', 'daily_activity_score']], on='idcol', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add active tod\n",
    "\n",
    "# Step 1: Group data by idcol and calculate interaction frequency for each time of day\n",
    "interaction_freq = data.groupby(['idcol', 'tod']).size().reset_index(name='freq')\n",
    "\n",
    "# Step 2: Find the time of day with the highest frequency for each user\n",
    "active_time_idx = interaction_freq.groupby('idcol')['freq'].idxmax()\n",
    "\n",
    "# Step 3: Extract the active time of day for each user\n",
    "active_time_per_user = interaction_freq.loc[active_time_idx, ['idcol', 'tod']]\n",
    "active_time_per_user.columns = ['idcol', 'active_time']\n",
    "\n",
    "# Step 4: Merge active time data back to the original DataFrame\n",
    "data = pd.merge(data, active_time_per_user, on='idcol', how='left')\n",
    "\n",
    "# Display the updated DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add user activity frequency:\n",
    "# Count the number of days that the user was active, and divide it by the number of days in the dataset:\n",
    "\n",
    "# Convert int_date to datetime\n",
    "data['int_date'] = pd.to_datetime(data['int_date'])\n",
    "\n",
    "# Calculate the total number of unique days in the dataset\n",
    "total_days = data[\"int_date\"].nunique()\n",
    "\n",
    "# Calculate the number of unique days each user had interactions\n",
    "user_unique_days = data.groupby('idcol')['int_date'].nunique()\n",
    "\n",
    "# Calculate the activity rate\n",
    "activity_rate = user_unique_days / total_days\n",
    "\n",
    "# Merge the activity_rate back into the original dataframe\n",
    "data = data.merge(activity_rate.rename('activity_rate'), on='idcol')\n",
    "\n",
    "\n",
    "# # Put activity rate into buns\n",
    "# data['activity_rate_bin'] = pd.qcut(data['activity_rate'], q=4, labels=['Low', 'Medium', 'High', 'VeryHigh'])\n",
    "# data.head(20)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add which day of the week they were most frequently active on:\n",
    "# Convert 'int_date' to datetime\n",
    "data['int_date'] = pd.to_datetime(data['int_date'])\n",
    "\n",
    "# Extract day of the week\n",
    "data['day_of_week'] = data['int_date'].dt.day_name()\n",
    "\n",
    "# Count interactions per user per day of the week\n",
    "interaction_counts = data.groupby(['idcol', 'day_of_week']).size().reset_index(name='count')\n",
    "\n",
    "# Find the most frequent day of the week for each user\n",
    "most_frequent_day = interaction_counts.loc[interaction_counts.groupby('idcol')['count'].idxmax()]\n",
    "\n",
    "# Merge this information back to the original dataframe\n",
    "data = data.merge(most_frequent_day[['idcol', 'day_of_week']], on='idcol', suffixes=('', '_most_frequent'))\n",
    "\n",
    "# Rename the column for clarity\n",
    "data.rename(columns={'day_of_week_most_frequent': 'most_frequent_day'}, inplace=True)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_interactions = data['idcol'].value_counts().reset_index()\n",
    "user_interactions.columns = ['idcol', 'user_interaction_count']\n",
    "\n",
    "# Calculate the total number of interactions in the dataset\n",
    "total_interactions = data.shape[0]\n",
    "\n",
    "# Merge the user interaction counts back into the original dataframe\n",
    "data = data.merge(user_interactions, on='idcol')\n",
    "\n",
    "# Bin the number of interactions:\n",
    "# data['num_interactions'] = pd.qcut(data['user_interaction_count'], q=4, labels=['Little', 'A bit more', 'Quite a few', 'This person has problems'])\n",
    "# data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Adding most clicked and most bought items and item types for each user:\n",
    "# clicks = data[data['interaction'] != 'DISPLAY']\n",
    "# most_clicked = clicks.groupby(['idcol', 'item']).size().reset_index(name='click_count')\n",
    "# most_clicked = most_clicked.loc[most_clicked.groupby('idcol')['click_count'].idxmax()][['idcol', 'item']]\n",
    "# most_clicked.rename(columns={'item': 'most_interacted_item'}, inplace=True)\n",
    "\n",
    "# # Merge the most clicked and most bought items back into the original DataFrame\n",
    "# data = data.merge(most_clicked, on='idcol', how='left')\n",
    "# # data = data.merge(most_bought, on='idcol', how='left')\n",
    "\n",
    "# data.head()\n",
    "\n",
    "# Filter out 'DISPLAY' interactions\n",
    "clicks = data[data['interaction'] != 'DISPLAY']\n",
    "\n",
    "# Group by idcol and item, and count the number of interactions\n",
    "interaction_counts = clicks.groupby(['idcol', 'item']).size().reset_index(name='interaction_count')\n",
    "\n",
    "# Sort interaction counts within each user group\n",
    "interaction_counts = interaction_counts.sort_values(by=['idcol', 'interaction_count'], ascending=[True, False])\n",
    "\n",
    "# Identify the most and second most interacted items\n",
    "most_interacted = interaction_counts.groupby('idcol').nth(0).reset_index()[['idcol', 'item']]\n",
    "most_interacted.rename(columns={'item': 'most_interacted_item'}, inplace=True)\n",
    "\n",
    "# second_most_interacted = interaction_counts.groupby('idcol').nth(1).reset_index()[['idcol', 'item']]\n",
    "# second_most_interacted.rename(columns={'item': 'second_most_interacted_item'}, inplace=True)\n",
    "\n",
    "# Merge the most and second most interacted items back into the original DataFrame\n",
    "data = data.merge(most_interacted, on='idcol', how='left')\n",
    "# data = data.merge(second_most_interacted, on='idcol', how='left')\n",
    "\n",
    "# Display the result\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding most interacted item type\n",
    "clicks = data[data['interaction'] != \"DISPLAY\"]\n",
    "most_clicked = clicks.groupby(['idcol', 'item_type']).size().reset_index(name='click_count')\n",
    "most_clicked = most_clicked.loc[most_clicked.groupby('idcol')['click_count'].idxmax()][['idcol', 'item_type']]\n",
    "most_clicked.rename(columns={'item_type': 'most_interacted'}, inplace=True)\n",
    "\n",
    "# # Determine the most bought item for each user\n",
    "# checkouts = data[data['interaction'] == 'CHECKOUT']\n",
    "# most_bought = checkouts.groupby(['idcol', 'item_type']).size().reset_index(name='checkout_count')\n",
    "# most_bought = most_bought.loc[most_bought.groupby('idcol')['checkout_count'].idxmax()][['idcol', 'item_type']]\n",
    "# most_bought.rename(columns={'item_type': 'most_bought_item_type'}, inplace=True)\n",
    "\n",
    "# Merge the most clicked and most bought items back into the original DataFrame\n",
    "data = data.merge(most_clicked, on='idcol', how='left')\n",
    "# data = data.merge(most_bought, on='idcol', how='left')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Item Features\n",
    "- Most bought by segment\n",
    "- Most bought by beh segment\n",
    "- Most clicked by segment\n",
    "- Most clicked by beh_segment\n",
    "- For this item, what is the ratio of checkouts to clicks over the entire dataset?\n",
    "- WHich screen was this item accessed from the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add number of unique users per item and normalise it per column:\n",
    "# Calculate the number of unique users per item\n",
    "unique_users_per_item = data.groupby('item')['idcol'].nunique().reset_index()\n",
    "unique_users_per_item.columns = ['item', 'unique_user_count']\n",
    "\n",
    "# Merge this information back into the original dataframe\n",
    "data = data.merge(unique_users_per_item, on='item', how='left')\n",
    "\n",
    "# Print skewness to determine bins:\n",
    "# skewness_pd = pd.Series(data[\"unique_user_count\"]).skew()\n",
    "# print(skewness_pd)\n",
    "\n",
    "# Apply log transformation to reduce skewness:\n",
    "# data['log_unique_user_count'] = data['unique_user_count'].apply(np.log)\n",
    "\n",
    "# skewness_pd = pd.Series(data[\"log_unique_user_count\"]).skew()\n",
    "# print(skewness_pd)\n",
    "# data['item_popularity'] = pd.qcut(data['unique_user_count'], q=6, labels=[\"Unknown\", \"Somewhat known\", \"known\", \"mildly popular\", \"popular\", \"Taylor Swift\"])\n",
    "# data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by item and find the mode of day_of_week\n",
    "most_frequent_day_per_item = data.groupby('item')['day_of_week'].agg(lambda x: x.mode()[0])\n",
    "\n",
    "# Add it as a new column in the DataFrame\n",
    "data['most_frequent_day_item'] = data['item'].map(most_frequent_day_per_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the activity score into bins:\n",
    "no_duplicate_data = data.drop_duplicates(subset=[\"idcol\"])\n",
    "\n",
    "# Calculate the number of bins using Doane's formula\n",
    "N = no_duplicate_data[\"idcol\"].nunique() # Number of users\n",
    "print(N)\n",
    "g1 = no_duplicate_data[\"daily_activity_score\"].skew()\n",
    "k = 1 + np.log2(N) + np.log2(1 + abs(g1) / np.sqrt(6))\n",
    "print(g1)\n",
    "# Round up the number of bins to the nearest integer\n",
    "num_bins = int(np.ceil(k))\n",
    "\n",
    "# Create bins\n",
    "bins = pd.qcut(no_duplicate_data['daily_activity_score'], q=num_bins,duplicates=\"drop\")\n",
    "\n",
    "# Assign bins to a new column\n",
    "no_duplicate_data['daily_activity_score_bin'] = bins\n",
    "\n",
    "no_duplicate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put the activity_rate into bins:\n",
    "# no_duplicate_data = data.drop_duplicates(subset=[\"idcol\"])\n",
    "\n",
    "# Calculate the number of bins using Doane's formula\n",
    "N = no_duplicate_data[\"idcol\"].nunique() # Number of users\n",
    "print(N)\n",
    "g1 = no_duplicate_data[\"activity_rate\"].skew()\n",
    "k = 1 + np.log2(N) + np.log2(1 + abs(g1) / np.sqrt(6))\n",
    "print(g1)\n",
    "# Round up the number of bins to the nearest integer\n",
    "num_bins = int(np.ceil(k))\n",
    "\n",
    "# Create bins\n",
    "bins = pd.qcut(no_duplicate_data['activity_rate'], q=num_bins,duplicates=\"drop\")\n",
    "\n",
    "# Assign bins to a new column\n",
    "no_duplicate_data['activity_rate_bin'] = bins\n",
    "\n",
    "no_duplicate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put the user_interaction_count into bins:\n",
    "# no_duplicate_data = data.drop_duplicates(subset=[\"idcol\"])\n",
    "\n",
    "# Calculate the number of bins using Doane's formula\n",
    "N = no_duplicate_data[\"idcol\"].nunique() # Number of users\n",
    "print(N)\n",
    "g1 = no_duplicate_data[\"user_interaction_count\"].skew()\n",
    "k = 1 + np.log2(N) + np.log2(1 + abs(g1) / np.sqrt(6))\n",
    "print(g1)\n",
    "# Round up the number of bins to the nearest integer\n",
    "num_bins = int(np.ceil(k))\n",
    "\n",
    "# Create bins\n",
    "bins = pd.qcut(no_duplicate_data['user_interaction_count'], q=num_bins,duplicates=\"drop\")\n",
    "\n",
    "# Assign bins to a new column\n",
    "no_duplicate_data['user_interaction_count_bin'] = bins\n",
    "\n",
    "no_duplicate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Put the unique_user into bins:\n",
    "# no_duplicate_data = data.drop_duplicates(subset=[\"idcol\"])\n",
    "\n",
    "# Calculate the number of bins using Doane's formula\n",
    "N = no_duplicate_data[\"item\"].nunique() # Number of items\n",
    "print(N)\n",
    "g1 = no_duplicate_data[\"unique_user_count\"].skew()\n",
    "k = 1 + np.log2(N) + np.log2(1 + abs(g1) / np.sqrt(6))\n",
    "print(g1)\n",
    "# Round up the number of bins to the nearest integer\n",
    "num_bins = int(np.ceil(k))\n",
    "\n",
    "# Create bins\n",
    "bins = pd.qcut(no_duplicate_data['unique_user_count'], q=num_bins,duplicates=\"drop\")\n",
    "\n",
    "# Assign bins to a new column\n",
    "no_duplicate_data['unique_user_count_bin'] = bins\n",
    "\n",
    "no_duplicate_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data = no_duplicate_data\n",
    "# Define the user columns, item columns and interaction columns:\n",
    "# u_cols = [\"idcol\", \"segment\", \"beh_segment\", \"active_ind\"] \n",
    "u_cols = [\"idcol\", \"segment\", \"beh_segment\", \"active_ind\", \"most_interacted\", \"most_interacted_item\", \"daily_activity_score_bin\",\"activity_rate_bin\" ,\"user_interaction_count_bin\",\n",
    "          \"most_frequent_day\"] \n",
    "\n",
    "\n",
    "item_cols = [\"item_id\", \"item_type\", \"unique_user_count_bin\", \"most_frequent_day_item\"]\n",
    "# item_cols = [\"item_id\", \"item_type\"]\n",
    "\n",
    "interact_cols = [\"idcol\", \"item_id\", \"interaction_scores\"]\n",
    "\n",
    "test_item_cols = [\"item_id\", \"item_type\", \"item\",\"unique_user_count_bin\"]\n",
    "\n",
    "test_items = no_duplicate_data[test_item_cols].copy()\n",
    "test_items = test_items.drop_duplicates()\n",
    "test_items = test_items.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Experiment 4:\n",
    "# u_cols = [\"idcol\", \"segment\", \"beh_segment\", \"active_ind\"]\n",
    "# item_cols = [\"item_id\", \"item\", \"item_type\"]\n",
    "\n",
    "# I want the interact_cols data in the following format:\n",
    "# \n",
    "\n",
    "user, item, rating = no_duplicate_data[u_cols].copy(), no_duplicate_data[item_cols].copy(), data[interact_cols].copy()\n",
    "\n",
    "# Accumulate rating data so that, for each unique user-item combination, there is a single row, otherwise the train-test split \n",
    "# have shared interactions. Can do an intelligent split, and use LightFM's built in weighting method,\n",
    "# but the weights matrix generated with that method is the exact same, even if I do the below:\n",
    "# This also allows us to incorporate the number of times that a user has interacted with an item as interaction weighting, implicitly\n",
    "rating = rating.groupby(['idcol', 'item_id'], as_index=False)['interaction_scores'].sum()\n",
    "\n",
    "\n",
    "# Drop duplicates, because I only need the unique items' and users' features:\n",
    "item = item.drop_duplicates()\n",
    "# item = item.drop(columns=[\"item\"], inplace=True)\n",
    "item = item.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "user = user.drop_duplicates()\n",
    "user = user.reset_index(drop=True)\n",
    "\n",
    "print(rating.shape)\n",
    "print(item.shape)\n",
    "print(user.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Clamp the interaction_scores to a maximum of 5\n",
    "# rating['interaction_scores'] = rating['interaction_scores'].clip(upper=5)\n",
    "display(rating.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the interaction scores:\n",
    "# Group by idcol and calculate the sum of interaction scores for each user\n",
    "sum_interaction_scores = rating.groupby('idcol')['interaction_scores'].sum()\n",
    "\n",
    "# Merge the sum of interaction scores back to the original DataFrame based on idcol\n",
    "rating = rating.merge(sum_interaction_scores.reset_index(), on='idcol', suffixes=('', '_sum'))\n",
    "\n",
    "# Calculate normalized interaction scores by dividing each interaction score by the sum\n",
    "rating['normalized_interaction_score'] = rating['interaction_scores'] / rating['interaction_scores_sum']\n",
    "\n",
    "# Replace NaN values with 0 in the normalized interaction scores column\n",
    "rating['normalized_interaction_score'].fillna(0, inplace=True)\n",
    "\n",
    "# Drop the temporary sum column\n",
    "rating.drop(columns=['interaction_scores_sum'], inplace=True)\n",
    "\n",
    "# Drop the unnormalised column\n",
    "rating.drop(columns=['interaction_scores'], inplace=True)\n",
    "\n",
    "# rename\n",
    "rating.rename(columns={'normalized_interaction_score': 'interaction_scores'}, inplace=True)\n",
    "\n",
    "# Display the DataFrame with the normalized interaction scores\n",
    "rating.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalise the user averages:\n",
    "# # Function to normalize a column\n",
    "# def normalize_column(df, column_name):\n",
    "#     min_value = df[column_name].min()\n",
    "#     max_value = df[column_name].max()\n",
    "#     df[column_name] = (df[column_name] - min_value) / (max_value - min_value)\n",
    "#     return df\n",
    "\n",
    "# # Normalize the numerical columns\n",
    "# numerical_columns = ['avg_daily_freq', 'avg_weekly_freq', 'avg_monthly_freq']\n",
    "\n",
    "# for column in numerical_columns:\n",
    "#     user = normalize_column(user, column)\n",
    "# pre_mol = rating[[\"idcol\", \"item_id\"]]\n",
    "# Create the pivot table\n",
    "# pivot_table = pre_mol.pivot_table(index='idcol', columns='item_id', aggfunc=len, fill_value=0)\n",
    "# Create pivot table with interaction_scores as values and idcol as index and item_id as columns\n",
    "pivot_table = rating.pivot_table(index='idcol', columns='item_id', values='interaction_scores', fill_value=0)\n",
    "\n",
    "\n",
    "slaasd = pivot_table.iloc[:12,:10]\n",
    "\n",
    "slaasd.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = rating.pivot_table(index='idcol', columns='item_id', values='interaction_scores', fill_value=0).round(2)\n",
    "\n",
    "# # Merge the two DataFrames on 'idcol' and 'item_id'\n",
    "# merged_df = pd.merge(slaasd, rating, on=['idcol', 'item_id'], how='left')\n",
    "\n",
    "# # Multiply the values in the interaction matrix by the corresponding interaction scores\n",
    "# for col in slaasd.columns[1:]:\n",
    "#     merged_df[col] *= merged_df['interaction_scores']\n",
    "\n",
    "# # Drop the 'interaction_scores' column\n",
    "# merged_df.drop('interaction_scores', axis=1, inplace=True)\n",
    "\n",
    "# # Pivot the DataFrame back to its original shape if needed\n",
    "# result_df = merged_df.pivot_table(index='idcol', columns='item_id', fill_value=0)\n",
    "\n",
    "# result_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Features Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalise the user feaetures column wise:\n",
    "\n",
    "# # Initialize the MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Select the columns to normalize\n",
    "# columns_to_normalize = ['daily_activity_score', 'activity_rate']\n",
    "\n",
    "# # Apply the scaler to the selected columns\n",
    "# user[columns_to_normalize] = scaler.fit_transform(user[columns_to_normalize])\n",
    "\n",
    "# # Display the result\n",
    "user.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train = pd.get_dummies(user,dtype = int, prefix=\"\", prefix_sep=\"\")\n",
    "user_features_col = user_train.drop(columns =['idcol']).columns.values\n",
    "user_feat = user_train.drop(columns =['idcol']).to_dict(orient='records')\n",
    "\n",
    "# user_train = user_train.sort_values(by='idcol', ascending=True)\n",
    "# print(user_feat)\n",
    "# user.shape\n",
    "# user.shape\n",
    "user_train.head(20)\n",
    "# print(user_features_col)\n",
    "for c in user_train.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gog = data.drop_duplicates()\n",
    "\n",
    "# # # Put a value of 0.5 at the second most interacted item:\n",
    "\n",
    "# # Create a dictionary mapping idcol to second_most_interacted_item\n",
    "# second_most_interacted_dict = gog.set_index('idcol')['second_most_interacted_item'].dropna().to_dict()\n",
    "\n",
    "# # Update user_train DataFrame using the dictionary\n",
    "# for idcol, itm in second_most_interacted_dict.items():\n",
    "#     user_train.loc[user_train['idcol'] == idcol, itm] = 0.5\n",
    "\n",
    "# # Display the result\n",
    "# # print(user_train)\n",
    "\n",
    "# user_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Features Data prep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = item.isna().sum()\n",
    "nan_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalise\n",
    "# # Initialize the MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Select the columns to normalize\n",
    "# columns_to_normalize = ['unique_users_segment1', 'unique_users_segment2', 'unique_users_segment3', 'unique_users_segment4']\n",
    "\n",
    "# # Apply the scaler to the selected columns\n",
    "# item[columns_to_normalize] = scaler.fit_transform(item[columns_to_normalize])\n",
    "\n",
    "# # Display the result\n",
    "# item.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item.head()\n",
    "\n",
    "item_features_df = pd.get_dummies(item, dtype = int, prefix=\"\", prefix_sep=\"\")\n",
    "# item_features[\"idcol\"] = data[\"idcol\"]\n",
    "item_features_col = item_features_df.drop(columns=['item_id']).columns.values\n",
    "\n",
    "\n",
    "# Need some for of identification for the item features\n",
    "# item_features[\"idcol\"] = data[\"idcol\"]\n",
    "\n",
    "\n",
    "item_features_df.fillna(value = 0, inplace=True)\n",
    "# item_features.shape\n",
    "# print(item_feat[0])\n",
    "# item.head()\n",
    "# print(item_features.iloc[0,:])\n",
    "# print(item_features_col)\n",
    "item_features_df.head()\n",
    "\n",
    "nan_columns = item_features_df.columns[item_features_df.isna().any()].tolist()\n",
    "\n",
    "item_feat = item_features_df.drop(columns =['item_id']).to_dict(orient='records')\n",
    "\n",
    "item_features_df.head()\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit into LightFM Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "users=[x for x in user_train['idcol']]\n",
    "\n",
    "items=[x for x in item['item_id']]\n",
    "\n",
    "\n",
    "# dataset.fit(users=users, items=items, user_features=user_features_col)\n",
    "dataset.fit(users=users, items=items, user_features=user_features_col, item_features=item_features_col)\n",
    "\n",
    "# num_users, num_items = dataset.interactions_shape()\n",
    "# print('Num users: {}, num_items {}.'.format(num_users, num_items))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Item Features to be fitted into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(item_features_col)\n",
    "# item_features = dataset.build_item_features(((x,y) for x,y in zip(item_features_df['item_id'],item_feat)), normalize=False)\n",
    "item_features = dataset.build_item_features(((x,item_features_col) for x in item_features_df['item_id']), normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(item_features.shape)\n",
    "# user_train.info()\n",
    "# user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build User Features to be fit into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_feat[0])\n",
    "user_features = dataset.build_user_features(((x,y) for x,y in zip(user_train['idcol'],user_feat)), normalize=False)\n",
    "\n",
    "# user_features = dataset.build_user_features(((x,user_features_col) for x in user_train['idcol']))\n",
    "\n",
    "# user_features_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build interactions (user â€” item) and its respective weights (in this case our custom weights - 0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# # We split the data into train and test by taking 20% of interactions for each user and moving that to the test set, i.e the training set will contain 80% of the items\n",
    "# # that the user interacted with\n",
    "\n",
    "# # Custom train-test split: Split the data into train and test before building interactions:\n",
    "# train_interactions = pd.DataFrame()\n",
    "# test_interaction = pd.DataFrame()\n",
    "\n",
    "# for user_id, group in rating.groupby('idcol'):\n",
    "#     if len(group) == 1:\n",
    "#         train_interactions = pd.concat([train_interactions, group])\n",
    "#     else:\n",
    "#         train_group, test_group = train_test_split(group, test_size=0.2, train_size=0.8, random_state=42)\n",
    "#         train_interactions = pd.concat([train_interactions, train_group])\n",
    "#         test_interaction = pd.concat([test_interaction, test_group])\n",
    "\n",
    "\n",
    "# (train, train_w) = dataset.build_interactions((x, y, w) for x,y,w in zip(train_interactions['idcol'], train_interactions['item_id'], train_interactions[\"interaction_scores\"]))\n",
    "# (test, test_w) = dataset.build_interactions((x, y, w) for x,y,w in zip(test_interaction['idcol'], test_interaction['item_id'], test_interaction[\"interaction_scores\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_interactions.shape)\n",
    "# print(test_interaction.shape)\n",
    "\n",
    "rating.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(interactions, weights) = dataset.build_interactions((x, y, w) for x,y,w in zip(rating['idcol'], rating['item_id'], rating[\"interaction_scores\"]))\n",
    "# (interactions, weights) = dataset.build_interactions((x, y) for x,y in zip(rating['idcol'], rating['item_id']))\n",
    "\n",
    "print(interactions.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL:\n",
    "train, test = random_train_test_split(interactions,test_percentage=0.2, random_state=42)\n",
    "train_w, test_w = random_train_test_split(weights, test_percentage=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "# Make a custom train-test split that uses either a_ the last 20% of interactions by date, or a random 20% of interactions for the test split\n",
    "# This ensures that there are no cold start users in the testing set. We will do cold-start testing in a different manner\n",
    "\n",
    "# SPlit the data from original data and then do all the data processing steps for each step separately. This ensures that the data doesn't bleed over into the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters:  {'no_components': 45, 'learning_rate': 0.09949391010649568, 'k': 19.29548285586018, 'n': 10.515335810044794}\n",
    "# Other best: {'no_components': 50, 'learning_rate': 0.08062443053534539, 'k': 9.583359248210815, 'n': 5.4809279704140055}.\n",
    "no_components = 45\n",
    "loss = 'warp'\n",
    "epoch = 30\n",
    "num_thread = 4\n",
    "learning_rate = 0.05\n",
    "max_sampled = 10\n",
    "# n = 5.4809279704140055\n",
    "# k = 9.583359248210815\n",
    "model = LightFM(no_components= no_components, loss=loss, random_state = 42, learning_rate=learning_rate, max_sampled=max_sampled)\n",
    "# model.fit(train,  user_features= user_features, item_features= item_features, epochs=epoch,num_threads = num_thread, sample_weight = train_w)\n",
    "\n",
    "# Experiemt 7\n",
    "# Training without user features\n",
    "model.fit(train, user_features= user_features, item_features=item_features, epochs=epoch,num_threads = num_thread, sample_weight = train_w)\n",
    "\n",
    "# Pure CF\n",
    "# model.fit(train, epochs=epoch,num_threads = num_thread)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=k, user_features=user_features,item_features=item_features,num_threads=num_thread).mean()\n",
    "test_precision = precision_at_k(model, test,train_interactions=train,item_features=item_features, k=k, user_features=user_features,num_threads=num_thread, preserve_rows = True)\n",
    "\n",
    "train_recall = recall_at_k(model, train, k=k, user_features=user_features,item_features=item_features, num_threads=num_thread).mean()\n",
    "test_recall = recall_at_k(model, test,train_interactions=train, k=k, user_features=user_features,item_features=item_features, num_threads=num_thread).mean()\n",
    "\n",
    "train_auc = auc_score(model, train, user_features=user_features,item_features=item_features, num_threads=num_thread).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train,item_features=item_features, user_features=user_features, num_threads=num_thread).mean()\n",
    "\n",
    "\n",
    "test_rr = reciprocal_rank(model, test, train_interactions=train, item_features=item_features,user_features=user_features).mean()\n",
    "train_rr = reciprocal_rank(model, train,item_features=item_features, user_features=user_features).mean()\n",
    "\n",
    "# # Round the float values\n",
    "# arr_rounded = np.round(test_precision, decimals=2)\n",
    "\n",
    "# # Count occurrences of each value\n",
    "# unique_values, counts = np.unique(arr_rounded, return_counts=True)\n",
    "\n",
    "# # Find the index of the maximum count\n",
    "# index_most_frequent_value = np.argmax(counts)\n",
    "\n",
    "# # Most frequent value after rounding\n",
    "# most_frequent_value = unique_values[index_most_frequent_value]\n",
    "\n",
    "print('Precision: train %.4f' % (train_precision))\n",
    "print('Precision: test %.4f' % (test_precision.mean()))\n",
    "\n",
    "# print('Precision: train %.4f' % (train_precision))\n",
    "print('Max Precision: test %.4f' % (test_precision.max()))\n",
    "# print(f\"Mode precision: {most_frequent_value}\")\n",
    "\n",
    "print('Recall: train %.4f' % (train_recall))\n",
    "print('Recall: test %.4f' % (test_recall))\n",
    "\n",
    "print('AUC: train %.4f' % (train_auc))\n",
    "print('AUC: test %.4f' % (test_auc))\n",
    "\n",
    "print('RR: train %.4f' % (train_rr))\n",
    "print('RR: test %.4f' % (test_rr))\n",
    "\n",
    "# Precision: train 0.3726\n",
    "# Precision: test 0.1495\n",
    "# Recall: train 0.9848\n",
    "# Recall: test 0.6412\n",
    "# AUC: train 0.9989\n",
    "# AUC: test 0.9041\n",
    "# RR: train 0.9867\n",
    "# RR: test 0.6524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "plt.plot(test_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the maximum attainable precision@k for each user\n",
    "# This is the precision when the top-k recommended items match the ground truth\n",
    "max_precisions = []\n",
    "for uid in range(test.shape[0]):\n",
    "    # Obtain the ground truth items for the user in the test set\n",
    "    ground_truth_items = test.getrow(uid).indices\n",
    "    \n",
    "    # Exclude users with no interactions in the test set\n",
    "    # if len(ground_truth_items) == 0:\n",
    "    #     continue\n",
    "    \n",
    "    # print(ground_truth_items)\n",
    "\n",
    "    # Calculate the maximum attainable precision@k for the user\n",
    "    max_precision = np.min([len(ground_truth_items), k]) / k\n",
    "    max_precisions.append(max_precision)\n",
    "\n",
    "# # Plot the maximum attainable precision@k for each user\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(max_precisions, label='Maximum Attainable Precision@{}'.format(k))\n",
    "# plt.xlabel('User ID')\n",
    "# plt.ylabel('Precision@{}'.format(k))\n",
    "# plt.title('Maximum Attainable Precision@{} for Each User'.format(k))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(max_precisions))\n",
    "print(test.shape[0])\n",
    "print(test_precision.shape)\n",
    "# Set figure size\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Create KDE plot\n",
    "sns.kdeplot(test_precision, label=\"Test\")\n",
    "sns.kdeplot(max_precisions, label=\"Truth\")\n",
    "# sns.histplot(test_precision, label=\"Test\")\n",
    "# sns.histplot(max_precisions, label=\"Truth\")\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Continuous Distribution of Values')\n",
    "plt.legend()\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# from lightfm import LightFM\n",
    "# from lightfm.datasets import fetch_movielens\n",
    "# from lightfm.evaluation import auc_score\n",
    "\n",
    "# # Fetch the dataset\n",
    "\n",
    "# def objective(trial):\n",
    "\n",
    "#     # Best hyperparameters:  {'no_components': 45, 'learning_rate': 0.09949391010649568, 'k': 19.29548285586018, 'n': 10.515335810044794}\n",
    "#     #  Other best: {'no_components': 50, 'learning_rate': 0.08062443053534539, 'k': 9.583359248210815, 'n': 5.4809279704140055}.\n",
    "#     # Define the hyperparameters to be tuned\n",
    "#     no_components = trial.suggest_int('no_components', 10, 50)\n",
    "#     learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)\n",
    "#     # item_alpha = trial.suggest_loguniform('item_alpha', 1e-6, 1e-1)\n",
    "#     # user_alpha = trial.suggest_loguniform('user_alpha', 1e-6, 1e-1)\n",
    "#     k = trial.suggest_loguniform('k', 5, 25)\n",
    "#     n = trial.suggest_loguniform('n', 5, 25)\n",
    "    \n",
    "#     # Create the LightFM model\n",
    "#     model = LightFM(\n",
    "#         loss='warp',\n",
    "#         no_components=no_components,\n",
    "#         learning_rate=learning_rate,\n",
    "#         # item_alpha=item_alpha,\n",
    "#         # user_alpha=user_alpha,\n",
    "#         k=k,\n",
    "#         n=n\n",
    "#     )\n",
    "#     model.fit(train,  user_features= user_features, item_features= item_features, epochs=epoch,num_threads = num_thread, sample_weight = train_w)\n",
    "    \n",
    "#     # Evaluate the model\n",
    "#     pak = precision_at_k(model, test,train_interactions=train, k=5,item_features=item_features, user_features=user_features, num_threads=num_thread).mean()\n",
    "    \n",
    "#     return pak\n",
    "\n",
    "# # Run the optimization\n",
    "# study = optuna.create_study(direction='maximize')\n",
    "# study.optimize(objective, n_trials=400)\n",
    "\n",
    "# print('Best hyperparameters: ', study.best_params)\n",
    "# np.save(\"BestParams.npy\", study.best_params)\n",
    "# print('Best precision@k=5: ', study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idcol = 77196041\n",
    "selected_user = data[data[\"active_ind\"]==\"Active\"].sample(n=1)\n",
    "target_idcol = selected_user[\"idcol\"].iloc[0]\n",
    "# target_idcol = 155531648\n",
    "print(target_idcol)\n",
    "# Rank the items based on interactions\n",
    "# Assign scores to interaction types\n",
    "# interaction_scores = {'DISPLAY': 0, 'CLICK': 1, 'CHECKOUT': 2}\n",
    "\n",
    "predict_user = data[data[\"idcol\"] == target_idcol]\n",
    "\n",
    "predict_user.head()\n",
    "\n",
    "# Map interaction types to scores\n",
    "predict_user['interaction_score'] = predict_user['interaction'].map(interaction_scores)\n",
    "\n",
    "# Rank items based on scores\n",
    "predict_user['item_rank'] = predict_user.groupby('idcol')['interaction_score'].rank(method='max', ascending=False)\n",
    "\n",
    "# Sort dataframe by item rank\n",
    "predict_user = predict_user.sort_values(by='item_rank')\n",
    "\n",
    "predict_user.head(-1)\n",
    "\n",
    "true_items = predict_user['item'].tolist()\n",
    "true_items = list(set(true_items))\n",
    "\n",
    "\n",
    "predict_user[u_cols].head(10)\n",
    "# Sit langs mekaar:\n",
    "# model recommendation, user se eie actual interactions, all items popularity over entire dataset, all item popularity for user segment, all item popularity for beh_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "map = dataset._user_id_mapping\n",
    "index = map[target_idcol]\n",
    "print(index)\n",
    "\n",
    "scores = model.predict(index, np.arange(103), user_features=user_features, item_features=item_features)\n",
    "\n",
    "# scores = model.predict(index, np.arange(103))\n",
    "# scores = model.predict(index, np.arange(103))\n",
    "# print(scores)\n",
    "# print(user.iloc[index,:])\n",
    "top_items = test_items.iloc[np.argsort(-scores)]\n",
    "# print(scores)\n",
    "# top_items.head()\n",
    "# # print(item.shape)\n",
    "# # print(top_items)\n",
    "# known_positives = item.iloc[interactions.tocsr()[index].indices]\n",
    "\n",
    "# top_items[0:10]\n",
    "recommended_list = top_items['item'].tolist()\n",
    "recommended_list = list(set(recommended_list))\n",
    "\n",
    "recommended_list_types = top_items['item_type'].tolist()\n",
    "recommended_list_types = list(set(recommended_list_types))\n",
    "\n",
    "print(true_items)\n",
    "print(recommended_list_types)\n",
    "\n",
    "# def precision_at_k(recommended_list, actual_list, k=10):\n",
    "#     # Get the intersection of the recommended list and the actual list up to k\n",
    "#     intersection = set(recommended_list[:k]) & set(actual_list)\n",
    "    \n",
    "#     # Calculate precision@k\n",
    "#     precision = len(intersection) / k\n",
    "    \n",
    "#     return precision\n",
    "\n",
    "# # Calculate precision@k=10\n",
    "# precision = precision_at_k(recommended_list, true_items, k=5)\n",
    "# print(\"Precision@k=10:\", precision)\n",
    "data.head()\n",
    "print(recommended_list.index(\"CTLN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank items over the entire dataset\n",
    "unique_user_counts = data.groupby('item')['idcol'].nunique().reset_index(name='unique_user_count')\n",
    "\n",
    "# Sort the items based on the count of unique users in descending order\n",
    "unique_user_counts = unique_user_counts.sort_values(by='unique_user_count', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "ranked_items = unique_user_counts[\"item\"].tolist()\n",
    "print(ranked_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rank items over the active user's segment\n",
    "\n",
    "segment_of_interest = predict_user[\"segment\"].iloc[0]\n",
    "segment_df = data[data['segment'] == segment_of_interest]\n",
    "\n",
    "unique_user_counts = segment_df.groupby('item')['idcol'].nunique().reset_index(name='unique_user_count')\n",
    "\n",
    "# Sort the items based on the count of unique users in descending order\n",
    "unique_user_counts = unique_user_counts.sort_values(by='unique_user_count', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "ranked_items_bysegment = unique_user_counts[\"item\"].tolist()\n",
    "print(ranked_items_bysegment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rank items over the active user's beh_segment\n",
    "\n",
    "\n",
    "segment_of_interest = predict_user[\"beh_segment\"].iloc[0]\n",
    "segment_df = data[data['beh_segment'] == segment_of_interest]\n",
    "\n",
    "unique_user_counts = segment_df.groupby('item')['idcol'].nunique().reset_index(name='unique_user_count')\n",
    "\n",
    "# Sort the items based on the count of unique users in descending order\n",
    "unique_user_counts = unique_user_counts.sort_values(by='unique_user_count', ascending=False)\n",
    "\n",
    "# Display the result\n",
    "ranked_items_bybehsegment = unique_user_counts[\"item\"].tolist()\n",
    "print(ranked_items_bybehsegment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the true items for the 2 next most similar users\n",
    "# First, lets find the two most similar users:\n",
    "def similar_users(user_id, model, N=10, norm = True):\n",
    "    user_bias ,user_representations = model.get_user_representations(features= user_features)\n",
    "    # user_bias ,user_representations = model.get_user_representations()\n",
    "\n",
    "    # Cosine similarity\n",
    "    scores = user_representations.dot(user_representations[user_id, :])\n",
    "    item_norms = np.linalg.norm(user_representations, axis=1)\n",
    "    \n",
    "    if norm == True:\n",
    "        scores /= item_norms\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best] / item_norms[user_id]), \n",
    "                    key=lambda x: -x[1])\n",
    "    else:\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best]), \n",
    "                    key=lambda x: -x[1])\n",
    "    return similar\n",
    "    \n",
    "# map = dataset._user_id_mapping\n",
    "# index = map[77196041]\n",
    "similar_item_list = similar_users(index,model, N = 3, norm=True)\n",
    "display(similar_item_list)\n",
    "similar_idx = [x[0] for x in similar_item_list]\n",
    "filtered_data = user.loc[similar_idx, :]\n",
    "filtered_data.head(20)\n",
    "\n",
    "two_users = filtered_data[\"idcol\"].tolist()[1:]\n",
    "print(two_users)\n",
    "\n",
    "next_two_users_items = []\n",
    "for id in two_users:\n",
    "    predict_user = data[data[\"idcol\"] == id]\n",
    "    true = predict_user['item'].tolist()\n",
    "    true = list(set(true))\n",
    "    next_two_users_items.append(true)\n",
    "\n",
    "\n",
    "print(next_two_users_items[1])\n",
    "\n",
    "# Function to look up item_type by item_id\n",
    "def get_item_type(item):\n",
    "    # Use loc to find the row where item_id matches and get the item_type\n",
    "    item_type = test_items.loc[test_items['item'] == item, 'item_type']\n",
    "    # Return the item_type if found, otherwise return None\n",
    "    return item_type.iloc[0] if not item_type.empty else None\n",
    "\n",
    "itm_tps = []\n",
    "for x in recommended_list:\n",
    "    itm_tps.append(get_item_type(x))\n",
    "\n",
    "true_item_types = []\n",
    "for x in true_items:\n",
    "    true_item_types.append(get_item_type(x))\n",
    "\n",
    "ranked_tps = []\n",
    "for x in ranked_items:\n",
    "    ranked_tps.append(get_item_type(x))\n",
    "\n",
    "rank_seg_tps = []\n",
    "for x in ranked_items_bysegment:\n",
    "    rank_seg_tps.append(get_item_type(x))\n",
    "\n",
    "rank_bseg_tps = []\n",
    "for x in ranked_items_bybehsegment:\n",
    "    rank_bseg_tps.append(get_item_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all those into a single dataframe so I can see them side by side\n",
    "num_item = len(true_items)\n",
    "max_length = 30\n",
    "# print(num_item)\n",
    "\n",
    "\n",
    "recdata = {\n",
    "    'True Items': true_items + [None] * (max_length - num_item),\n",
    "    'typs': true_item_types + [None] * (max_length - len(true_item_types)),\n",
    "    'User2' : next_two_users_items[0] + [None] * (max_length - len(next_two_users_items[0])),\n",
    "    'User3' : next_two_users_items[1] + [None] * (max_length - len(next_two_users_items[1])),\n",
    "    'Recommended Items': recommended_list[:max_length],\n",
    "    \"Rec itm types\": itm_tps[:max_length],\n",
    "    'Most Popular Tot': ranked_items[:max_length],\n",
    "    \"pop types\": ranked_tps[:max_length],\n",
    "    'Most Popular Seg': ranked_items_bysegment[:max_length],\n",
    "    \"popseg types\": rank_seg_tps[:max_length],\n",
    "    'Most Popular BSeg': ranked_items_bybehsegment[:max_length],\n",
    "    \"popbseg types\": rank_bseg_tps[:max_length],\n",
    "}\n",
    "\n",
    "# Create DataFrame from dictionary\n",
    "df = pd.DataFrame(recdata)\n",
    "\n",
    "def listwise_precision_at_k(recommended_list, actual_list, k=20):\n",
    "    # Get the intersection of the recommended list and the actual list up to k\n",
    "    intersection = set(recommended_list[:k]) & set(actual_list)\n",
    "    \n",
    "    # Calculate precision@k\n",
    "    precision = len(intersection) / k\n",
    "    \n",
    "    return precision\n",
    "\n",
    "print(listwise_precision_at_k(recommended_list, true_items))\n",
    "\n",
    "df.head(-1)\n",
    "\n",
    "\n",
    "# True items for next 2 most similar users\n",
    "# Recommend items' types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar Item Calculation using cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_items(item_id, model, N=10, norm = True):\n",
    "    item_bias ,item_representations = model.get_item_representations(features=item_features)\n",
    "\n",
    "    # Cosine similarity\n",
    "    scores = item_representations.dot(item_representations[item_id, :])\n",
    "    item_norms = np.linalg.norm(item_representations, axis=1)\n",
    "\n",
    "    if norm == True:\n",
    "        scores /= item_norms\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best]/ item_norms[item_id] ), key=lambda x: -x[1])\n",
    "    else:\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best] ), key=lambda x: -x[1])\n",
    "    return similar\n",
    "\n",
    "\n",
    "value_to_find = 'EBSH'\n",
    "value_to_compare = \"SEVP\"\n",
    "index = test_items['item'].eq(value_to_find).idxmax()\n",
    "print(index)\n",
    "similar_item_list = similar_items(index, model, N=103)\n",
    "\n",
    "simscores = [x[1] for x in similar_item_list]\n",
    "\n",
    "\n",
    "similar_idx = [x[0] for x in similar_item_list ]\n",
    "siitms = test_items.iloc[similar_idx]# Can also add the other\n",
    "\n",
    "siitms[\"scores\"] = simscores\n",
    "\n",
    "siitms.head(104)\n",
    "\n",
    "\n",
    "scores_column_name = \"scores\"  # Replace this with the actual column name\n",
    "\n",
    "# Filter the DataFrame based on the condition value_to_compare\n",
    "filtered_items = siitms[siitms[\"item\"] == value_to_compare]\n",
    "\n",
    "# Check if any items match the condition\n",
    "if not filtered_items.empty:\n",
    "    # Extract the score from the first matching item\n",
    "    compare_score = filtered_items.iloc[0][scores_column_name]\n",
    "    print(\"Comparison score:\", compare_score)\n",
    "else:\n",
    "    print(\"No items matching the condition:\", value_to_compare)\n",
    "\n",
    "# print(compare_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_items(item_id, model, N=10, norm = True):\n",
    "    item_bias ,item_representations = model.get_item_representations(features=item_features)\n",
    "\n",
    "    # Cosine similarity\n",
    "    scores = item_representations.dot(item_representations[item_id, :])\n",
    "    item_norms = np.linalg.norm(item_representations, axis=1)\n",
    "\n",
    "    if norm == True:\n",
    "        scores /= item_norms\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best]/ item_norms[item_id] ), key=lambda x: -x[1])\n",
    "    else:\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best] ), key=lambda x: -x[1])\n",
    "    return similar\n",
    "\n",
    "\n",
    "value_to_find = 'EBSH'\n",
    "index = test_items['item'].eq(value_to_find).idxmax()\n",
    "print(index)\n",
    "similar_item_list = similar_items(index, model, N=10)\n",
    "\n",
    "simscores = [x[1] for x in similar_item_list]\n",
    "\n",
    "\n",
    "similar_idx = [x[0] for x in similar_item_list ]\n",
    "siitms = test_items.iloc[similar_idx]# Can also add the other\n",
    "\n",
    "siitms[\"scores\"] = simscores\n",
    "\n",
    "siitms.head(104)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = siitms.isna().sum()\n",
    "nan_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar User Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_users(user_id, model, N=10, norm = True):\n",
    "    user_bias ,user_representations = model.get_user_representations(features= user_features)\n",
    "\n",
    "    # Cosine similarity\n",
    "    scores = user_representations.dot(user_representations[user_id, :])\n",
    "    item_norms = np.linalg.norm(user_representations, axis=1)\n",
    "    \n",
    "    if norm == True:\n",
    "        scores /= item_norms\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best] / item_norms[user_id]), \n",
    "                    key=lambda x: -x[1])\n",
    "    else:\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best]), \n",
    "                    key=lambda x: -x[1])\n",
    "    return similar\n",
    "    \n",
    "# map = dataset._user_id_mapping\n",
    "# index = map[77196041]\n",
    "similar_item_list = similar_users(index,model, N = 3)\n",
    "print(similar_item_list)\n",
    "similar_idx = [x[0] for x in similar_item_list]\n",
    "filtered_data = user.loc[similar_idx, :]\n",
    "filtered_data.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(u_cols)\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# lists = []\n",
    "# for index, row in filtered_data.iterrows():\n",
    "#     print(row)\n",
    "#     break\n",
    "#     userlst = []\n",
    "#     pos_idxs = row[row == 1].index.tolist()\n",
    "#     userlst.append(filtered_data.iloc[i,0])\n",
    "#     userlst += pos_idxs\n",
    "    \n",
    "#     i+=1\n",
    "#     lists.append(userlst)\n",
    "\n",
    "\n",
    "# new_df = pd.DataFrame(data = lists, columns = u_cols)\n",
    "# new_df.head(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cold Start Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# from scipy import sparse\n",
    "\n",
    "# def format_newuser_input(user_feature_map, user_feature_list):\n",
    "#   num_features = len(user_feature_list)\n",
    "#   normalised_val = 1.0 \n",
    "#   target_indices = []\n",
    "#   for feature in user_feature_list:\n",
    "#     try:\n",
    "#         target_indices.append(user_feature_map[feature])\n",
    "#     except KeyError:\n",
    "#         print(\"new user feature encountered '{}'\".format(feature))\n",
    "#         pass\n",
    "\n",
    "#   new_user_features = np.zeros(len(user_feature_map.keys()))\n",
    "#   for i in target_indices:\n",
    "#     new_user_features[i] = normalised_val\n",
    "#   new_user_features = sparse.csr_matrix(new_user_features)\n",
    "#   return(new_user_features)\n",
    "\n",
    "# user_id_map, user_feature_map, item_id_map, item_feature_map = dataset.mapping()\n",
    "# user_feature_list = [\"segment4\", \"B01\", \"Cold Start\"]\n",
    "\n",
    "# new_user_features = format_newuser_input(user_feature_map, u_cols)\n",
    "# scores = model.predict(0, np.arange(104), user_features=new_user_features)\n",
    "\n",
    "# top_items = item.iloc[np.argsort(-scores)]\n",
    "\n",
    "# top_items.head()\n",
    "\n",
    "# new_user = pd.DataFrame(np.zeros(len(user_features_col))).T\n",
    "# new_user.columns = user_features_col\n",
    "# # print(new_user)\n",
    "\n",
    "# new_user.head()\n",
    "\n",
    "\n",
    "# new_user_id = 86000\n",
    "# new_user['segment4'] = 1\n",
    "# new_user['B50'] = 1\n",
    "# new_user['Cold Start'] = 1\n",
    "\n",
    "# new_user = csr_matrix(new_user)\n",
    "# scores = model.predict(user_ids = 0,item_ids = np.arange(interactions.shape[1]), user_features=new_user)\n",
    "# top_items_new_user = item.iloc[np.argsort(-scores)]\n",
    "# top_items_new_user[0:10]\n",
    "user.head()\n",
    "user.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our isolated user to check our algorithm:\n",
    "# We predict items for this user, then check the precision at k=5.\n",
    "\n",
    "idcol = 99999999999\n",
    "segment = \"segment4\"\n",
    "beh_segment = \"B07\"\n",
    "active_ind = \"Cold Start\"\n",
    "\n",
    "column_names = u_cols\n",
    "# Populate the new DataFrame with relevant information from the original DataFrame\n",
    "new_user_data = {\n",
    "    'idcol': idcol,\n",
    "    'segment': segment,\n",
    "    'beh_segment': beh_segment,\n",
    "    'active_ind': active_ind,\n",
    "    'most_interacted': np.nan,\n",
    "    'most_interacted_item': np.nan,\n",
    "    'daily_activity_score_bin': np.nan,\n",
    "    'activity_rate_bin': np.nan,\n",
    "    'user_interaction_count_bin': np.nan,\n",
    "    'most_frequent_day': np.nan\n",
    "}\n",
    "\n",
    "print(new_user_data)\n",
    "\n",
    "new_user = pd.DataFrame(new_user_data, index=[0])\n",
    "\n",
    "# Function to fill NaN values in the new row\n",
    "# def fill_na_with_mode_or_mean(data, cold_start_user):\n",
    "#     filled_row = cold_start_user.copy()\n",
    "    \n",
    "#     for column in data.columns:\n",
    "#         if cold_start_user[column].isna().any():\n",
    "#             if data[column].dtype == 'object':  # Categorical data\n",
    "#                 mode_value = data[column].mode()[0]\n",
    "#                 filled_row[column].fillna(mode_value, inplace=True)\n",
    "#             else:  # Numerical data\n",
    "#                 mean_value = data[column].mean()\n",
    "#                 filled_row[column].fillna(mean_value, inplace=True)\n",
    "    \n",
    "#     return filled_row\n",
    "\n",
    "def fill_na_with_mode_or_mean(data, cold_start_user):\n",
    "    filled_row = cold_start_user.copy()\n",
    "    # data = data.astype(str)\n",
    "    for column in data.columns:\n",
    "        if cold_start_user[column].isna().any():\n",
    "            if pd.api.types.is_object_dtype(data[column]):  # Categorical data\n",
    "                mode_value = data[column].mode()[0]\n",
    "                filled_row[column].fillna(mode_value, inplace=True)\n",
    "            elif pd.api.types.is_numeric_dtype(data[column]):  # Numeric data\n",
    "                mean_value = data[column].mean()\n",
    "                filled_row[column].fillna(mean_value, inplace=True)\n",
    "            elif pd.api.types.is_categorical_dtype(data[column]):  # Check if dtype is categorical\n",
    "                mode_value = data[column].mode()[0]\n",
    "                filled_row[column].fillna(mode_value, inplace=True)\n",
    "    \n",
    "    return filled_row\n",
    "\n",
    "new_user_completed = fill_na_with_mode_or_mean(user, new_user)\n",
    "# new_user_sparse = pd.get_dummies(new_user_completed,dtype = int, prefix=\"\", prefix_sep=\"\")\n",
    "# # new_user_sparse.head()\n",
    "new_user_completed.head()\n",
    "# print(len(user_features_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.999, 1.25]\n",
    "# (1.25, 1.5]\n",
    "# (1.5, 1.667]\n",
    "# (1.667, 1.833]\n",
    "# (1.833, 2.0]\n",
    "# (2.0, 2.25]\n",
    "# (2.25, 2.5]\n",
    "# (2.5, 2.833]\n",
    "# (2.833, 3.0]\n",
    "# (3.0, 3.5]\n",
    "# (3.5, 65.0]\n",
    "\n",
    "# (0.0104, 0.0227]\n",
    "# (0.0227, 0.0341]\n",
    "# (0.0341, 0.0455]\n",
    "# (0.0455, 0.0568]\n",
    "# (0.0568, 0.0795]\n",
    "# (0.0795, 0.557]\n",
    "\n",
    "# (0.999, 2.0]\n",
    "# (2.0, 3.0]\n",
    "# (3.0, 4.0]\n",
    "# (4.0, 5.0]\n",
    "# (5.0, 6.0]\n",
    "# (6.0, 7.0]\n",
    "# (7.0, 9.0]\n",
    "# (9.0, 11.0]\n",
    "# (11.0, 16.0]\n",
    "# (16.0, 204.0]\n",
    "# print(user_features_col)\n",
    "# user_train.head()\n",
    "# print(\n",
    "# user[\"activity_rate_bin\"].unique())\n",
    "user.head()\n",
    "# print(type(user[\"daily_activity_score_bin\"].unique()[0]))\n",
    "# print(type(new_user_completed[\"daily_activity_score_bin\"].iloc[0]))\n",
    "\n",
    "# print(user[\"daily_activity_score_bin\"].unique()[0])\n",
    "# print(new_user_completed[\"daily_activity_score_bin\"].iloc[0])\n",
    "\n",
    "# print(new_user_completed[\"daily_activity_score_bin\"].iloc[0] == user[\"daily_activity_score_bin\"].astype(str).unique()[0])\n",
    "\n",
    "# user_bins_str = [str(interval) for interval in user[\"daily_activity_score_bin\"].unique()]\n",
    "# new_user_completed_bins_str = [str(interval) for interval in new_user_completed[\"daily_activity_score_bin\"].unique()]\n",
    "\n",
    "# # Compare the intervals as strings\n",
    "# print(new_user_completed_bins_str[0] == user_bins_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_wide = pd.DataFrame(np.zeros(len(user_features_col))).T\n",
    "new_user_wide.columns = user_features_col\n",
    "new_user_wide.reset_index(drop=True, inplace=True)\n",
    "# print(new_user_wide)\n",
    "\n",
    "# Populate segment columns\n",
    "segments = ['segment1', 'segment2', 'segment3', 'segment4']\n",
    "for segment in segments:\n",
    "    new_user_wide[segment] = (new_user_completed['segment'] == segment).astype(int)\n",
    "\n",
    "# Populate behavior segment columns\n",
    "beh_segments = ['B{:02d}'.format(i) for i in range(1, 51)]\n",
    "beh_segments.remove(\"B43\")\n",
    "beh_segments.remove(\"B45\")\n",
    "for beh_segment in beh_segments:\n",
    "    new_user_wide[beh_segment] = (new_user_completed['beh_segment'] == beh_segment).astype(int)\n",
    "\n",
    "# Convert index values of new_user_wide to strings\n",
    "new_user_wide.index = new_user_wide.index.astype(str)\n",
    "\n",
    "\n",
    "# Populate other columns\n",
    "bins1 = [str(interval) for interval in user[\"daily_activity_score_bin\"].unique()]\n",
    "for bin in bins1:\n",
    "    # print(new_user_completed[column])\n",
    "    # print(new_user_wide.index)\n",
    "    # break\n",
    "    new_user_wide[bin] = int((bin == [str(interval) for interval in new_user_completed[\"daily_activity_score_bin\"].unique()][0]))\n",
    "\n",
    "# Populate other columns\n",
    "bins2 = [str(interval) for interval in user[\"activity_rate_bin\"].unique()]\n",
    "for bin in bins2:\n",
    "    # print(new_user_completed[column])\n",
    "    # print(new_user_wide.index)\n",
    "    # break\n",
    "    new_user_wide[bin] = int((bin == [str(interval) for interval in new_user_completed[\"activity_rate_bin\"].unique()][0]))\n",
    "# Populate other columns\n",
    "bins3 = [str(interval) for interval in user[\"user_interaction_count_bin\"].unique()]\n",
    "for bin in bins3:\n",
    "    # print(new_user_completed[column])\n",
    "    # print(new_user_wide.index)\n",
    "    # break\n",
    "    new_user_wide[bin] = int((bin == [str(interval) for interval in new_user_completed[\"user_interaction_count_bin\"].unique()][0]))\n",
    "\n",
    "days = ['Monday', \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "for day in days:\n",
    "    print(new_user_completed['most_frequent_day'] == day)\n",
    "    new_user_wide[day] = int(new_user_completed['most_frequent_day'] == day)\n",
    "\n",
    "# Print the populated sparse DataFrame\n",
    "# print(new_user_wide)\n",
    "new_user_wide.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in new_user_wide.columns:\n",
    "    print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_csr = csr_matrix(new_user_wide)\n",
    "# new_user = csr_matrix(new_user)\n",
    "print(new_user_csr.shape)\n",
    "scores = model.predict(user_ids = 0,item_ids = np.arange(interactions.shape[1]), user_features=new_user_csr, item_features=item_features)\n",
    "top_items_new_user = test_items.iloc[np.argsort(scores)]\n",
    "top_items_new_user[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_features.shape)\n",
    "\n",
    "\n",
    "new_user_completed_dum = pd.get_dummies(new_user_completed,dtype = int, prefix=\"\", prefix_sep=\"\")\n",
    "# user_features_col = new_user_completed_dum.drop(columns =['idcol']).columns.values\n",
    "cold_user_feat = new_user_completed_dum.drop(columns =['idcol']).to_dict(orient='records')\n",
    "\n",
    "new_user_completed_dum = new_user_completed_dum.sort_values(by='idcol', ascending=True)\n",
    "new_user_wide[\"idcol\"] = idcol\n",
    "print(user_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = new_user_wide.columns\n",
    "# B = user_train.columns\n",
    "# # Convert lists to sets\n",
    "# set_A = set(A)\n",
    "# set_B = set(B)\n",
    "\n",
    "# # Values in list A that are not in list B\n",
    "# result = list(set_A - set_B)\n",
    "\n",
    "# print(user_feat)  # Output: [1, 2]\n",
    "\n",
    "# new_user_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=[x for x in user_train['idcol']] + [idcol]\n",
    "\n",
    "all_users = user_feat + cold_user_feat\n",
    "\n",
    "# dataset.fit(users=users, items=items, user_features=user_features_col)\n",
    "dataset.fit(users=users, items=items, user_features=user_features_col, item_features=item_features_col)\n",
    "\n",
    "cold_user_features = dataset.build_user_features(((x,y) for x,y in zip(new_user_wide['idcol'],all_users)), normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_users(user_id, model, N=10, norm = True):\n",
    "    user_bias ,user_representations = model.get_user_representations(features= cold_user_features)\n",
    "\n",
    "    # Cosine similarity\n",
    "    scores = user_representations.dot(user_representations[user_id, :])\n",
    "    item_norms = np.linalg.norm(user_representations, axis=1)\n",
    "    \n",
    "    if norm == True:\n",
    "        scores /= item_norms\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best] / item_norms[user_id]), \n",
    "                    key=lambda x: -x[1])\n",
    "    else:\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        similar = sorted(zip(best, scores[best]), \n",
    "                    key=lambda x: -x[1])\n",
    "    return similar\n",
    "    \n",
    "map = dataset._user_id_mapping\n",
    "index = map[99999999999]\n",
    "similar_item_list = similar_users(index,model, N = 3)\n",
    "print(similar_item_list)\n",
    "similar_idx = [x[0] for x in similar_item_list]\n",
    "filtered_data = user.loc[similar_idx, :]\n",
    "filtered_data.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
